# VPipe 代码走查实战

## 🎯 目标

通过具体的代码走查示例，帮助你深入理解VPipe的执行流程。

---

## 实战1: 完整启动流程追踪

### 场景：启动4-GPU BERT训练

**命令**:
```bash
cd runtime
python driver.py --config_file configs/bert_4vpipe.yml
```

### 执行流程详解

#### Step 1: driver.py 解析配置
**文件**: `driver.py`, Line 77-105

```python
# 解析命令行参数
args = parser.parse_args()  # config_file = 'configs/bert_4vpipe.yml'

# 读取YAML配置
with open(args.config_file, 'r') as stream:
    configurations = yaml.load(stream, Loader=yaml.FullLoader)
    
# configurations 内容:
{
    'directory': 'bert',
    'module': 'vgpus=4',
    'partition': 'vgpus=4/vpipe.json',
    'machines': ['localhost:0', 'localhost:1', 'localhost:2', 'localhost:3'],
    'sync_mode': 'asp',
    'batch_size': 16,
    ...
}
```

#### Step 2: 解析机器列表
**文件**: `driver.py`, Line 153-163

```python
# 解析每个GPU的信息
workers = []  # 存储所有worker信息
for machine in configurations['machines']:
    # 'localhost:0' -> ip='localhost', gpu_id='0'
    machine_info = machine.split(":")
    workers.append(WorkerInfo(ip=machine_info[0], gpu_id=machine_info[1]))

# 结果:
workers = [
    WorkerInfo(ip='localhost', gpu_id=0),
    WorkerInfo(ip='localhost', gpu_id=1),
    WorkerInfo(ip='localhost', gpu_id=2),
    WorkerInfo(ip='localhost', gpu_id=3)
]
```

#### Step 3: 构建启动命令
**文件**: `driver.py`, Line 196-264

```python
# 构建runtime命令
runtime_cmd = 'main_with_runtime.py ' \
              '--data_dir /data/run01/.../bert_dataset ' \
              '--master_addr localhost ' \
              '--module vgpus=4 ' \
              '--checkpoint_dir /output/2025-10-27T10:30:00 ' \
              '--partition vgpus=4/vpipe.json ' \
              '--sync_mode asp ' \
              '--distributed_backend gloo ' \
              '-b 16 ' \
              '--lr 0.03 ' \
              '--epochs 2 '
```

#### Step 4: 启动容器和进程
**文件**: `driver.py`, Line 267-313

```python
for node_rank, (node_ip, workers) in enumerate(nodes_to_workers_mapping.items()):
    # 构建singularity命令
    singularity_cmd = 'singularity exec --nv --writable-tmpfs ' \
                     '-B $(dirname $PWD):/workspace ' \
                     '/path/to/vpipe.sif /bin/bash -c'
    
    # 使用launch模块启动多进程
    launch_module = '-m launch ' \
                   '--nnodes 1 ' \      # 1个节点
                   '--node_rank 0 ' \   # 节点rank
                   '--nproc_per_node 4' # 每节点4个进程
    
    # 完整命令
    full_cmd = f"{singularity_cmd} 'python {launch_module} {runtime_cmd}'"
    
    # 启动子进程
    subprocess.Popen(full_cmd, shell=True)
```

**实际执行的命令**（简化版）:
```bash
singularity exec --nv --writable-tmpfs vpipe.sif \
  python -m launch --nnodes 1 --node_rank 0 --nproc_per_node 4 \
  main_with_runtime.py --data_dir /data/... --module vgpus=4 ...
```

---

## 实战2: 单个Rank的初始化过程

### 场景：Rank 2 (Stage 1, 第一个GPU) 的初始化

#### Step 1: main_with_runtime.py 入口
**文件**: `bert/main_with_runtime.py`, Line 577-607

```python
def main():
    args = parser.parse_args()
    
    # torch.distributed 已经由 launch.py 初始化
    # 此时环境变量中已有:
    #   RANK=2
    #   LOCAL_RANK=2  
    #   WORLD_SIZE=4
    #   MASTER_ADDR=localhost
    #   MASTER_PORT=29500
    
    args.rank = dist.get_rank()        # = 2
    args.world_size = dist.get_world_size()  # = 4
    
    # 设置CUDA设备
    torch.cuda.set_device(args.local_rank)  # GPU 2
    
    # 读取partition配置
    with open(args.partition, 'r') as f:
        partition = json.load(f)
    # partition = {"partition": [12, 13, 13, 11], "recompute_ratio": [0.3, 0, 0, 0]}
    
    # 调用stage函数构建模型
    stage(args)
```

#### Step 2: stage() 函数构建模型
**文件**: `bert/main_with_runtime.py`, Line 180-400

```python
def stage(args):
    # 1. 读取BERT配置
    config = BertConfig.from_json_file(args.bert_config)
    
    # 2. 读取partition配置
    with open(args.partition, 'r') as f:
        partition_data = json.load(f)
    partition_list = partition_data['partition']  # [12, 13, 13, 11]
    recompute_ratio = partition_data['recompute_ratio']  # [0.3, 0, 0, 0]
    
    # 3. 生成stage映射
    # partition [12, 13, 13, 11] 表示:
    #   Stage 0: 第0-11层   (12层)
    #   Stage 1: 第12-24层  (13层)  <- Rank 2 属于这里
    #   Stage 2: 第25-37层  (13层)
    #   Stage 3: 第38-48层  (11层)
    
    module_to_stage_map = []
    for stage_id, num_modules in enumerate(partition_list):
        module_to_stage_map.extend([stage_id] * num_modules)
    
    # module_to_stage_map = [0]*12 + [1]*13 + [2]*13 + [3]*11
    
    # 4. 生成stage到rank的映射
    stage_to_rank_map = {
        0: [0],    # Stage 0 只在 rank 0
        1: [1],    # Stage 1 只在 rank 1
        2: [2],    # Stage 2 只在 rank 2
        3: [3]     # Stage 3 只在 rank 3
    }
    
    # 5. 构建BERT模型并切分
    from vpipe import Bert, Stage
    
    # 读取BERT的declares和calculations字符串
    bert_model = Bert(declares=bert_declares_str, calculations=bert_calculations_str)
    bert_model.generate_layer_blocks()
    
    # 6. 为当前rank生成对应的stage代码
    my_stage_id = 1  # Rank 2 对应 Stage 1
    start_block = 12  # Stage 1从第12层开始
    end_block = 25    # 到第24层结束
    
    declares, calcus, inputs, outputs = bert_model.generate_stage(start_block, end_block)
    
    # 7. 创建Stage模块
    fraction = recompute_ratio[my_stage_id]  # = 0 (Stage 1不重计算)
    stage_module = Stage(inputs, outputs, declares, calcus, fraction)
    
    # 8. 构建模型描述 (用于runtime)
    model = [
        (stage_module, inputs, outputs)  # (module, input_names, output_names)
    ]
    
    # 9. 定义tensor shapes
    training_tensor_shapes = {
        "input0": (batch_size, seq_len),           # input_ids
        "input1": (batch_size, seq_len),           # segment_ids  
        "input2": (batch_size, 1, 1, seq_len),     # attention_mask
        "out12": (batch_size, seq_len, hidden),    # Stage 1的输入
        "out25": (batch_size, seq_len, hidden),    # Stage 1的输出
    }
    
    # 10. 构建configuration_maps
    configuration_maps = {
        'module_to_stage_map': module_to_stage_map,
        'stage_to_rank_map': stage_to_rank_map,
        'stage_to_depth_map': None  # 使用默认计算
    }
    
    # 11. 创建StageRuntime
    r = runtime.StageRuntime(
        model=model,
        distributed_backend='gloo',
        fp16=False,
        loss_scale=1,
        training_tensor_shapes=training_tensor_shapes,
        eval_tensor_shapes=eval_tensor_shapes,
        training_tensor_dtypes=training_tensor_dtypes,
        inputs_module_destinations=inputs_module_destinations,
        target_tensor_names={'target'},
        configuration_maps=configuration_maps,
        master_addr='localhost',
        rank=2,              # 当前rank
        local_rank=2,        # 本地rank
        num_ranks_in_server=1,  # 单节点多进程，每进程独立
        verbose_freq=0,
        model_type='bert'
    )
```

#### Step 3: StageRuntime 初始化
**文件**: `runtime.py`, Line 45-80

```python
class StageRuntime:
    def __init__(self, ...):
        # 保存基本信息
        self.rank = 2
        self.local_rank = 2
        self.distributed_backend = 'gloo'
        self.fp16 = False
        self.training_tensor_shapes = training_tensor_shapes
        
        # 调用initialize
        self.initialize(model, inputs_module_destinations, configuration_maps, ...)
```

**文件**: `runtime.py`, Line 81-291

```python
def initialize(self, model, ...):
    # 1. 初始化通信相关变量
    self.send_ranks = {}
    self.receive_ranks = {}
    self.tensor_tags = {}
    
    # 2. 确定当前stage
    rank_to_stage_map = {}
    for stage in stage_to_rank_map:
        for rank in stage_to_rank_map[stage]:
            rank_to_stage_map[rank] = stage
    
    self.stage = rank_to_stage_map[self.rank]  # self.stage = 1
    
    # 3. 确定前后stage的ranks
    self.num_stages = 4
    self.rank_in_stage = 0
    self.num_ranks_in_stage = 1
    
    self.ranks_in_previous_stage = [0]  # Stage 0的ranks
    self.ranks_in_next_stage = [2]      # Stage 2的ranks
    
    # 4. 确定需要通信的tensors
    # Stage 1需要:
    #   - 从Stage 0接收: out12 (Stage 0的输出)
    #   - 发送到Stage 2: out25 (Stage 1的输出)
    
    for i in range(len(model_all_stages) - 1):
        for tensor_name in model_all_stages[i][2]:  # 第i个stage的输出
            if tensor_name in model_all_stages[i+1][1]:  # 第i+1个stage的输入
                # 如果i+1是我的stage，需要接收
                if module_to_stage_map[i+1] == self.stage:
                    self.receive_ranks[tensor_name] = stage_to_rank_map[module_to_stage_map[i]]
                # 如果i是我的stage，需要发送
                if module_to_stage_map[i] == self.stage:
                    self.send_ranks[tensor_name] = stage_to_rank_map[module_to_stage_map[i+1]]
    
    # 对于Rank 2 (Stage 1):
    self.receive_ranks = {'out12': [0]}  # 从rank 0接收out12
    self.send_ranks = {'out25': [2]}     # 发送out25到rank 2 (实际上是rank 3)
    
    # 注意: 这里有个错误，应该是发送到rank 3，说明配置需要调整
    # 正确的应该是:
    self.send_ranks = {'out25': [3]}     # 发送到下一个stage的第一个rank
    
    # 5. 分配tensor tags
    self.tensor_tags = {
        'input0': 1,
        'input1': 2,
        'input2': 3,
        'out12': 4,
        'out25': 5,
        'out38': 6,
        'target': 7,
        'ack': 8
    }
    
    # 6. 创建CommunicationHandler
    self.comm_handler = communication.CommunicationHandler(
        master_addr='localhost',
        master_port=12345,
        rank=2,
        local_rank=2,
        num_ranks_in_server=1,
        world_size=4,
        fp16=False,
        backend='gloo'
    )
    
    # 7. 将模块移到GPU
    modules = self.modules_with_dependencies.modules()
    for i in range(len(modules)):
        modules[i] = modules[i].cuda()  # 移到GPU 2
    
    # 8. 初始化通信handler
    self.comm_handler.initialize(
        self.receive_ranks,
        self.send_ranks,
        self.tensor_tags,
        ...
    )
```

---

## 实战3: 一次训练迭代的完整流程

### 场景：4个stages的流水线执行

假设batch_size=16，每个minibatch=4，则有4个minibatches。

#### 时间线示意图

```
Time  |  Stage 0 (Rank 0)  |  Stage 1 (Rank 1)  |  Stage 2 (Rank 2)  |  Stage 3 (Rank 3)
------+--------------------+--------------------+--------------------+-------------------
  0   |  F0 (forward mb0)  |                    |                    |
  1   |  F1                |  F0                |                    |
  2   |  F2                |  F1                |  F0                |
  3   |  F3                |  F2                |  F1                |  F0
  4   |  B3 (backward mb3) |  F3                |  F2                |  F1
  5   |  B2                |  B3                |  F3                |  F2
  6   |  B1                |  B2                |  B3                |  F3
  7   |  B0                |  B1                |  B2                |  B3
  8   |                    |  B0                |  B1                |  B2
  9   |                    |                    |  B0                |  B1
 10   |                    |                    |                    |  B0
```

#### 详细代码追踪：Rank 2 (Stage 2) 的执行

**文件**: `runtime.py`, `run_training_iteration()`

```python
def run_training_iteration(self, num_iterations):
    """
    对于Rank 2:
    - num_warmup_minibatches = 2 (需要等待前2个stage)
    - num_iterations = 4 (4个minibatches)
    """
    
    # ===== Warmup 阶段 =====
    
    # Iteration 0: 只接收和前向
    for i in range(self.num_warmup_minibatches):  # i=0,1
        # 1. 接收来自Stage 1的激活值
        self.receive_tensors_forward()
        #   从rank 1接收 out25
        #   self.tensors = [{'out25': tensor}]
        
        # 2. 执行前向传播
        self.run_forward()
        #   执行 Stage 2 的forward
        #   self.tensors[-1]['out38'] = stage2_module(self.tensors[-1]['out25'])
        
        # 3. 发送激活值到Stage 3
        self.send_tensors_forward()
        #   发送 out38 到 rank 3
        
        self.forward_minibatch_id += 1  # 0 -> 1 -> 2
    
    # 此时 forward_minibatch_id = 2, backward_minibatch_id = 0
    
    # ===== 稳定阶段 (1F1B) =====
    
    for i in range(num_iterations - self.num_warmup_minibatches):  # i=0,1
        # Iteration 2: 1次前向 + 1次后向
        
        # 4. 继续前向
        self.receive_tensors_forward()  # 接收mb2的激活值
        self.run_forward()
        self.send_tensors_forward()
        self.forward_minibatch_id += 1  # 2 -> 3
        
        # 5. 后向传播
        self.receive_tensors_backward()
        #   从rank 3接收 out38的梯度
        #   self.gradients['out38'] = grad_tensor
        
        self.run_backward()
        #   执行反向传播
        #   计算 out25 的梯度
        #   self.gradients['out25'] = ...
        
        self.send_tensors_backward()
        #   发送 out25的梯度 到 rank 1
        
        self.backward_minibatch_id += 1  # 0 -> 1
    
    # ===== Cooldown 阶段 =====
    
    for i in range(self.num_warmup_minibatches):  # i=0,1
        # 只执行后向
        self.receive_tensors_backward()
        self.run_backward()
        self.send_tensors_backward()
        self.backward_minibatch_id += 1  # 1 -> 2 -> 3
```

---

## 实战4: 通信细节追踪

### 场景：Rank 1发送激活值到Rank 2

#### Rank 1 (发送方)
**文件**: `runtime.py`, `send_tensors_forward()`

```python
def send_tensors_forward(self):
    # Stage 1发送 out25 到 Stage 2
    for output_name in self.send_ranks:  # output_name = 'out25'
        if output_name == "ack":
            continue
        
        # 获取要发送的tensor
        tensor = self.tensors[-1][output_name]
        # tensor.shape = (4, 128, 1024)  # (batch, seq_len, hidden)
        
        # 调用通信handler发送
        self.comm_handler.send(
            output_name,                          # 'out25'
            tensor,                               # 激活值tensor
            forward_minibatch_id=self.forward_minibatch_id,  # 2
            backward_minibatch_id=self.backward_minibatch_id, # 0
            backward=False
        )
    
    # 增加消息索引
    self.comm_handler.increment_messaging_index(sending=True)
```

**文件**: `communication.py`, `send()`

```python
def send(self, tensor_name, tensor, forward_minibatch_id, 
         backward_minibatch_id, backward=False):
    # tensor_name = 'out25', backward = False
    
    # 1. 确定目标rank
    if not backward:
        dst_ranks = self.send_ranks[tensor_name]  # [2]
    
    # 2. 选择一个目标rank（如果有多个，轮询）
    dst_rank = dst_ranks[self.messaging_index_send % len(dst_ranks)]  # rank 2
    
    # 3. 获取tensor的tag
    tag = self.tensor_tags[tensor_name]  # 假设 tag=5
    
    # 4. 添加minibatch_id到tag
    adjusted_tag = tag * 100000 + forward_minibatch_id
    # adjusted_tag = 5 * 100000 + 2 = 500002
    
    # 5. 将tensor放入发送队列
    self.forward_send_queues[tensor_name].put((tensor, dst_rank, adjusted_tag))
    
    # 后台线程会异步发送:
    # dist.send(tensor=tensor, dst=2, tag=500002)
```

#### Rank 2 (接收方)
**文件**: `runtime.py`, `receive_tensors_forward()`

```python
def receive_tensors_forward(self):
    self.tensors.append({})  # 新建一个字典存储这个minibatch的tensors
    
    # Stage 2需要接收 out25
    for input_name in self.receive_ranks:  # input_name = 'out25'
        if input_name == "ack":
            continue
        
        # 调用通信handler接收
        received_tensor = self.comm_handler.recv(
            input_name,                               # 'out25'
            forward_minibatch_id=self.forward_minibatch_id,  # 2
            backward_minibatch_id=self.backward_minibatch_id, # 0
            backward=False
        )
        
        self.tensors[-1][input_name] = received_tensor
        # self.tensors[-1] = {'out25': received_tensor}
    
    self.comm_handler.increment_messaging_index(sending=False)
```

**文件**: `communication.py`, `recv()`

```python
def recv(self, tensor_name, forward_minibatch_id, 
         backward_minibatch_id, backward=False):
    # tensor_name = 'out25', backward = False
    
    # 1. 确定源rank
    if not backward:
        src_ranks = self.receive_ranks[tensor_name]  # [1]
    
    # 2. 选择一个源rank
    src_rank = src_ranks[self.messaging_index_receive % len(src_ranks)]  # rank 1
    
    # 3. 计算tag
    tag = self.tensor_tags[tensor_name]  # 5
    adjusted_tag = tag * 100000 + forward_minibatch_id  # 500002
    
    # 4. 从接收队列中获取（后台线程已接收）
    result = self.forward_receive_queues[tensor_name].get()
    # result = (received_tensor,)
    
    return result[0]
    
    # 后台线程执行的是:
    # buffer = torch.zeros(shape, dtype=dtype, device='cuda')
    # dist.recv(tensor=buffer, src=1, tag=500002)
    # queue.put((buffer,))
```

---

## 实战5: Weight Stashing机制

### 场景：Rank 1执行ASP模式训练

**背景**: 
- Pipeline深度为4，所以num_versions=4
- 在时刻t，Stage 1可能在用v0版本做前向，同时用v3版本的梯度更新权重

#### 权重版本队列示意

```python
# 初始化时
self.queue = deque([
    state_dict_v0,  # 最老
    state_dict_v1,
    state_dict_v2,
    state_dict_v3   # 最新
], maxlen=4)

self.latest_version = Version(3)
self.current_version = Version(0)  # 用于前向
```

#### 一次训练迭代

**文件**: `optimizer.py`, `step()`

```python
def step(self):
    # 1. 加载旧版本权重（用于应用梯度）
    self.load_old_params()
    #   从队列头部取出v0的权重
    #   将模型参数设置为v0
    
    # 2. 应用梯度更新
    self.base_optimizer.step()
    #   使用当前的梯度更新v0的权重 -> 得到v4
    
    # 3. 保存新版本
    new_state_dict = self.get_params(clone=True)
    self.queue.append(new_state_dict)
    #   队列变为: [v1, v2, v3, v4]
    #   v0被自动丢弃（maxlen=4）
    
    # 4. 更新版本号
    self.latest_version = self.latest_version.incr()  # v3 -> v4
    self.current_version = self.current_version.incr()  # v0 -> v1
    
    # 5. 加载新版本（用于下次前向）
    self.load_new_params()
    #   将模型参数设置为v4
```

#### 版本对应关系

```
Minibatch   Forward用的版本   Backward用的版本   更新后的版本
   0            v0                -              -
   1            v1                -              -
   2            v2                -              -
   3            v3                -              -
   4            v4              v0 (mb0的梯度)   v0 -> v4
   5            v5              v1 (mb1的梯度)   v1 -> v5
   6            v6              v2 (mb2的梯度)   v2 -> v6
   ...
```

**关键点**: 
- mb4的前向用的是v4，但同时在用mb0的梯度更新v0
- 这保证了梯度版本一致性：mb0前向用v0，反向也对应v0

---

## 实战6: 激活重计算

### 场景：Stage 0启用recompute_ratio=0.3

**Stage 0包含12个blocks，recompute_ratio=0.3**

#### 前向传播时

**文件**: `bert/vpipe.py`, `Stage.forward()`

```python
def forward(self, *args):
    # 假设Stage 0有12个blocks，recompute_ratio=0.3
    # back = int(0.3 * 12) = 3
    # 所以后3个blocks使用checkpoint
    
    if self.enable_recompute:
        # 1. 前9个blocks正常执行
        exec(self.no_cp)
        # self.no_cp 包含:
        #   out0 = args[0]
        #   out1 = self.layer1(out0)
        #   ...
        #   out9 = self.layer9(out8)
        #   cp_out = cp.checkpoint(self.cp_forward, out9, self.dummy)
        #   self.out = (cp_out[0], cp_out[1], ...)
        
        # 2. 后3个blocks通过checkpoint执行
        # checkpoint不会保存中间激活值
        
    else:
        # 完全正常执行
        exec(self.no_cp)
    
    return self.out
```

#### 反向传播时

```python
# 当计算梯度时，PyTorch的autograd会:
# 1. 对于前9个blocks: 直接使用保存的激活值
# 2. 对于后3个blocks: 重新执行cp_forward来计算激活值

def cp_forward(self, *args):
    # 重计算后3个blocks
    exec(self.cp)
    # self.cp 包含:
    #   out9 = args[0]
    #   out10 = self.layer10(out9)
    #   out11 = self.layer11(out10)
    #   out12 = self.layer12(out11)
    #   self.cp_out = (out10, out11, out12)
    return self.cp_out
```

#### 内存节省计算

假设每个block的激活值占100MB：
- **不重计算**: 12 * 100MB = 1200MB
- **重计算30%**: 9 * 100MB = 900MB (节省300MB)
- **代价**: 反向时多3次前向计算

---

## 实战7: 调试技巧实战

### 技巧1: 打印每个stage的执行时间

在 `runtime.py` 中添加：

```python
def run_training_iteration(self, num_iterations, start_iter=0):
    import time
    
    for i in range(start_iter, num_iterations):
        # 前向
        start_time = time.time()
        self.receive_tensors_forward()
        recv_time = time.time() - start_time
        
        start_time = time.time()
        self.run_forward()
        forward_time = time.time() - start_time
        
        start_time = time.time()
        self.send_tensors_forward()
        send_time = time.time() - start_time
        
        if i % 10 == 0:
            print(f"[Rank {self.rank}] Iter {i}: "
                  f"recv={recv_time*1000:.2f}ms, "
                  f"forward={forward_time*1000:.2f}ms, "
                  f"send={send_time*1000:.2f}ms")
```

### 技巧2: 验证通信的tensor值

```python
def send_tensors_forward(self):
    for output_name in self.send_ranks:
        tensor = self.tensors[-1][output_name]
        
        # 打印tensor统计信息
        print(f"[Rank {self.rank}] Sending {output_name}: "
              f"shape={tensor.shape}, "
              f"mean={tensor.mean().item():.4f}, "
              f"std={tensor.std().item():.4f}, "
              f"min={tensor.min().item():.4f}, "
              f"max={tensor.max().item():.4f}")
        
        self.comm_handler.send(...)
```

### 技巧3: 追踪梯度流

```python
def run_backward(self):
    # 执行反向前
    for name, param in self.modules()[0].named_parameters():
        if param.grad is not None:
            print(f"[Rank {self.rank}] Before backward, {name}.grad = "
                  f"{param.grad.norm().item():.6f}")
    
    # 执行反向传播
    ...
    
    # 执行反向后
    for name, param in self.modules()[0].named_parameters():
        if param.grad is not None:
            print(f"[Rank {self.rank}] After backward, {name}.grad = "
                  f"{param.grad.norm().item():.6f}")
```

### 技巧4: 可视化pipeline

创建一个日志记录器：

```python
# 在runtime.py开头添加
import json
import time

class PipelineLogger:
    def __init__(self, rank, log_file):
        self.rank = rank
        self.log_file = log_file
        self.events = []
    
    def log_event(self, event_type, minibatch_id):
        self.events.append({
            'rank': self.rank,
            'event': event_type,
            'minibatch': minibatch_id,
            'time': time.time()
        })
    
    def save(self):
        with open(self.log_file, 'w') as f:
            json.dump(self.events, f)

# 在StageRuntime中使用
self.logger = PipelineLogger(self.rank, f'pipeline_rank{self.rank}.json')

def receive_tensors_forward(self):
    self.logger.log_event('recv_forward_start', self.forward_minibatch_id)
    ...
    self.logger.log_event('recv_forward_end', self.forward_minibatch_id)
```

然后用Python脚本可视化：

```python
import json
import matplotlib.pyplot as plt

# 读取所有ranks的日志
events = []
for rank in range(4):
    with open(f'pipeline_rank{rank}.json', 'r') as f:
        events.extend(json.load(f))

# 按时间排序
events.sort(key=lambda x: x['time'])

# 绘制甘特图
fig, ax = plt.subplots(figsize=(12, 6))
colors = {'recv_forward': 'blue', 'forward': 'green', 'send_forward': 'red'}

for event in events:
    ax.barh(event['rank'], 0.1, left=event['time'], color=colors.get(event['event'], 'gray'))

ax.set_xlabel('Time (s)')
ax.set_ylabel('Rank')
ax.set_title('Pipeline Execution Timeline')
plt.savefig('pipeline_timeline.png')
```

---

## 总结

通过这些实战示例，你应该能够：

1. **理解启动流程**: 从driver到runtime的完整链路
2. **追踪执行流**: 单个rank的初始化和运行
3. **分析流水线**: 4个stages如何协同工作
4. **理解通信**: tensor如何在stages间传递
5. **掌握Weight Stashing**: 权重版本如何管理
6. **理解重计算**: 如何用时间换内存
7. **调试技巧**: 如何定位和分析问题

建议你实际运行代码，添加这些调试语句，观察实际的执行情况！

