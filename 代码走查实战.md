# VPipe ä»£ç èµ°æŸ¥å®æˆ˜

## ğŸ¯ ç›®æ ‡

é€šè¿‡å…·ä½“çš„ä»£ç èµ°æŸ¥ç¤ºä¾‹ï¼Œå¸®åŠ©ä½ æ·±å…¥ç†è§£VPipeçš„æ‰§è¡Œæµç¨‹ã€‚

---

## å®æˆ˜1: å®Œæ•´å¯åŠ¨æµç¨‹è¿½è¸ª

### åœºæ™¯ï¼šå¯åŠ¨4-GPU BERTè®­ç»ƒ

**å‘½ä»¤**:
```bash
cd runtime
python driver.py --config_file configs/bert_4vpipe.yml
```

### æ‰§è¡Œæµç¨‹è¯¦è§£

#### Step 1: driver.py è§£æé…ç½®
**æ–‡ä»¶**: `driver.py`, Line 77-105

```python
# è§£æå‘½ä»¤è¡Œå‚æ•°
args = parser.parse_args()  # config_file = 'configs/bert_4vpipe.yml'

# è¯»å–YAMLé…ç½®
with open(args.config_file, 'r') as stream:
    configurations = yaml.load(stream, Loader=yaml.FullLoader)
    
# configurations å†…å®¹:
{
    'directory': 'bert',
    'module': 'vgpus=4',
    'partition': 'vgpus=4/vpipe.json',
    'machines': ['localhost:0', 'localhost:1', 'localhost:2', 'localhost:3'],
    'sync_mode': 'asp',
    'batch_size': 16,
    ...
}
```

#### Step 2: è§£ææœºå™¨åˆ—è¡¨
**æ–‡ä»¶**: `driver.py`, Line 153-163

```python
# è§£ææ¯ä¸ªGPUçš„ä¿¡æ¯
workers = []  # å­˜å‚¨æ‰€æœ‰workerä¿¡æ¯
for machine in configurations['machines']:
    # 'localhost:0' -> ip='localhost', gpu_id='0'
    machine_info = machine.split(":")
    workers.append(WorkerInfo(ip=machine_info[0], gpu_id=machine_info[1]))

# ç»“æœ:
workers = [
    WorkerInfo(ip='localhost', gpu_id=0),
    WorkerInfo(ip='localhost', gpu_id=1),
    WorkerInfo(ip='localhost', gpu_id=2),
    WorkerInfo(ip='localhost', gpu_id=3)
]
```

#### Step 3: æ„å»ºå¯åŠ¨å‘½ä»¤
**æ–‡ä»¶**: `driver.py`, Line 196-264

```python
# æ„å»ºruntimeå‘½ä»¤
runtime_cmd = 'main_with_runtime.py ' \
              '--data_dir /data/run01/.../bert_dataset ' \
              '--master_addr localhost ' \
              '--module vgpus=4 ' \
              '--checkpoint_dir /output/2025-10-27T10:30:00 ' \
              '--partition vgpus=4/vpipe.json ' \
              '--sync_mode asp ' \
              '--distributed_backend gloo ' \
              '-b 16 ' \
              '--lr 0.03 ' \
              '--epochs 2 '
```

#### Step 4: å¯åŠ¨å®¹å™¨å’Œè¿›ç¨‹
**æ–‡ä»¶**: `driver.py`, Line 267-313

```python
for node_rank, (node_ip, workers) in enumerate(nodes_to_workers_mapping.items()):
    # æ„å»ºsingularityå‘½ä»¤
    singularity_cmd = 'singularity exec --nv --writable-tmpfs ' \
                     '-B $(dirname $PWD):/workspace ' \
                     '/path/to/vpipe.sif /bin/bash -c'
    
    # ä½¿ç”¨launchæ¨¡å—å¯åŠ¨å¤šè¿›ç¨‹
    launch_module = '-m launch ' \
                   '--nnodes 1 ' \      # 1ä¸ªèŠ‚ç‚¹
                   '--node_rank 0 ' \   # èŠ‚ç‚¹rank
                   '--nproc_per_node 4' # æ¯èŠ‚ç‚¹4ä¸ªè¿›ç¨‹
    
    # å®Œæ•´å‘½ä»¤
    full_cmd = f"{singularity_cmd} 'python {launch_module} {runtime_cmd}'"
    
    # å¯åŠ¨å­è¿›ç¨‹
    subprocess.Popen(full_cmd, shell=True)
```

**å®é™…æ‰§è¡Œçš„å‘½ä»¤**ï¼ˆç®€åŒ–ç‰ˆï¼‰:
```bash
singularity exec --nv --writable-tmpfs vpipe.sif \
  python -m launch --nnodes 1 --node_rank 0 --nproc_per_node 4 \
  main_with_runtime.py --data_dir /data/... --module vgpus=4 ...
```

---

## å®æˆ˜2: å•ä¸ªRankçš„åˆå§‹åŒ–è¿‡ç¨‹

### åœºæ™¯ï¼šRank 2 (Stage 1, ç¬¬ä¸€ä¸ªGPU) çš„åˆå§‹åŒ–

#### Step 1: main_with_runtime.py å…¥å£
**æ–‡ä»¶**: `bert/main_with_runtime.py`, Line 577-607

```python
def main():
    args = parser.parse_args()
    
    # torch.distributed å·²ç»ç”± launch.py åˆå§‹åŒ–
    # æ­¤æ—¶ç¯å¢ƒå˜é‡ä¸­å·²æœ‰:
    #   RANK=2
    #   LOCAL_RANK=2  
    #   WORLD_SIZE=4
    #   MASTER_ADDR=localhost
    #   MASTER_PORT=29500
    
    args.rank = dist.get_rank()        # = 2
    args.world_size = dist.get_world_size()  # = 4
    
    # è®¾ç½®CUDAè®¾å¤‡
    torch.cuda.set_device(args.local_rank)  # GPU 2
    
    # è¯»å–partitioné…ç½®
    with open(args.partition, 'r') as f:
        partition = json.load(f)
    # partition = {"partition": [12, 13, 13, 11], "recompute_ratio": [0.3, 0, 0, 0]}
    
    # è°ƒç”¨stageå‡½æ•°æ„å»ºæ¨¡å‹
    stage(args)
```

#### Step 2: stage() å‡½æ•°æ„å»ºæ¨¡å‹
**æ–‡ä»¶**: `bert/main_with_runtime.py`, Line 180-400

```python
def stage(args):
    # 1. è¯»å–BERTé…ç½®
    config = BertConfig.from_json_file(args.bert_config)
    
    # 2. è¯»å–partitioné…ç½®
    with open(args.partition, 'r') as f:
        partition_data = json.load(f)
    partition_list = partition_data['partition']  # [12, 13, 13, 11]
    recompute_ratio = partition_data['recompute_ratio']  # [0.3, 0, 0, 0]
    
    # 3. ç”Ÿæˆstageæ˜ å°„
    # partition [12, 13, 13, 11] è¡¨ç¤º:
    #   Stage 0: ç¬¬0-11å±‚   (12å±‚)
    #   Stage 1: ç¬¬12-24å±‚  (13å±‚)  <- Rank 2 å±äºè¿™é‡Œ
    #   Stage 2: ç¬¬25-37å±‚  (13å±‚)
    #   Stage 3: ç¬¬38-48å±‚  (11å±‚)
    
    module_to_stage_map = []
    for stage_id, num_modules in enumerate(partition_list):
        module_to_stage_map.extend([stage_id] * num_modules)
    
    # module_to_stage_map = [0]*12 + [1]*13 + [2]*13 + [3]*11
    
    # 4. ç”Ÿæˆstageåˆ°rankçš„æ˜ å°„
    stage_to_rank_map = {
        0: [0],    # Stage 0 åªåœ¨ rank 0
        1: [1],    # Stage 1 åªåœ¨ rank 1
        2: [2],    # Stage 2 åªåœ¨ rank 2
        3: [3]     # Stage 3 åªåœ¨ rank 3
    }
    
    # 5. æ„å»ºBERTæ¨¡å‹å¹¶åˆ‡åˆ†
    from vpipe import Bert, Stage
    
    # è¯»å–BERTçš„declareså’Œcalculationså­—ç¬¦ä¸²
    bert_model = Bert(declares=bert_declares_str, calculations=bert_calculations_str)
    bert_model.generate_layer_blocks()
    
    # 6. ä¸ºå½“å‰rankç”Ÿæˆå¯¹åº”çš„stageä»£ç 
    my_stage_id = 1  # Rank 2 å¯¹åº” Stage 1
    start_block = 12  # Stage 1ä»ç¬¬12å±‚å¼€å§‹
    end_block = 25    # åˆ°ç¬¬24å±‚ç»“æŸ
    
    declares, calcus, inputs, outputs = bert_model.generate_stage(start_block, end_block)
    
    # 7. åˆ›å»ºStageæ¨¡å—
    fraction = recompute_ratio[my_stage_id]  # = 0 (Stage 1ä¸é‡è®¡ç®—)
    stage_module = Stage(inputs, outputs, declares, calcus, fraction)
    
    # 8. æ„å»ºæ¨¡å‹æè¿° (ç”¨äºruntime)
    model = [
        (stage_module, inputs, outputs)  # (module, input_names, output_names)
    ]
    
    # 9. å®šä¹‰tensor shapes
    training_tensor_shapes = {
        "input0": (batch_size, seq_len),           # input_ids
        "input1": (batch_size, seq_len),           # segment_ids  
        "input2": (batch_size, 1, 1, seq_len),     # attention_mask
        "out12": (batch_size, seq_len, hidden),    # Stage 1çš„è¾“å…¥
        "out25": (batch_size, seq_len, hidden),    # Stage 1çš„è¾“å‡º
    }
    
    # 10. æ„å»ºconfiguration_maps
    configuration_maps = {
        'module_to_stage_map': module_to_stage_map,
        'stage_to_rank_map': stage_to_rank_map,
        'stage_to_depth_map': None  # ä½¿ç”¨é»˜è®¤è®¡ç®—
    }
    
    # 11. åˆ›å»ºStageRuntime
    r = runtime.StageRuntime(
        model=model,
        distributed_backend='gloo',
        fp16=False,
        loss_scale=1,
        training_tensor_shapes=training_tensor_shapes,
        eval_tensor_shapes=eval_tensor_shapes,
        training_tensor_dtypes=training_tensor_dtypes,
        inputs_module_destinations=inputs_module_destinations,
        target_tensor_names={'target'},
        configuration_maps=configuration_maps,
        master_addr='localhost',
        rank=2,              # å½“å‰rank
        local_rank=2,        # æœ¬åœ°rank
        num_ranks_in_server=1,  # å•èŠ‚ç‚¹å¤šè¿›ç¨‹ï¼Œæ¯è¿›ç¨‹ç‹¬ç«‹
        verbose_freq=0,
        model_type='bert'
    )
```

#### Step 3: StageRuntime åˆå§‹åŒ–
**æ–‡ä»¶**: `runtime.py`, Line 45-80

```python
class StageRuntime:
    def __init__(self, ...):
        # ä¿å­˜åŸºæœ¬ä¿¡æ¯
        self.rank = 2
        self.local_rank = 2
        self.distributed_backend = 'gloo'
        self.fp16 = False
        self.training_tensor_shapes = training_tensor_shapes
        
        # è°ƒç”¨initialize
        self.initialize(model, inputs_module_destinations, configuration_maps, ...)
```

**æ–‡ä»¶**: `runtime.py`, Line 81-291

```python
def initialize(self, model, ...):
    # 1. åˆå§‹åŒ–é€šä¿¡ç›¸å…³å˜é‡
    self.send_ranks = {}
    self.receive_ranks = {}
    self.tensor_tags = {}
    
    # 2. ç¡®å®šå½“å‰stage
    rank_to_stage_map = {}
    for stage in stage_to_rank_map:
        for rank in stage_to_rank_map[stage]:
            rank_to_stage_map[rank] = stage
    
    self.stage = rank_to_stage_map[self.rank]  # self.stage = 1
    
    # 3. ç¡®å®šå‰åstageçš„ranks
    self.num_stages = 4
    self.rank_in_stage = 0
    self.num_ranks_in_stage = 1
    
    self.ranks_in_previous_stage = [0]  # Stage 0çš„ranks
    self.ranks_in_next_stage = [2]      # Stage 2çš„ranks
    
    # 4. ç¡®å®šéœ€è¦é€šä¿¡çš„tensors
    # Stage 1éœ€è¦:
    #   - ä»Stage 0æ¥æ”¶: out12 (Stage 0çš„è¾“å‡º)
    #   - å‘é€åˆ°Stage 2: out25 (Stage 1çš„è¾“å‡º)
    
    for i in range(len(model_all_stages) - 1):
        for tensor_name in model_all_stages[i][2]:  # ç¬¬iä¸ªstageçš„è¾“å‡º
            if tensor_name in model_all_stages[i+1][1]:  # ç¬¬i+1ä¸ªstageçš„è¾“å…¥
                # å¦‚æœi+1æ˜¯æˆ‘çš„stageï¼Œéœ€è¦æ¥æ”¶
                if module_to_stage_map[i+1] == self.stage:
                    self.receive_ranks[tensor_name] = stage_to_rank_map[module_to_stage_map[i]]
                # å¦‚æœiæ˜¯æˆ‘çš„stageï¼Œéœ€è¦å‘é€
                if module_to_stage_map[i] == self.stage:
                    self.send_ranks[tensor_name] = stage_to_rank_map[module_to_stage_map[i+1]]
    
    # å¯¹äºRank 2 (Stage 1):
    self.receive_ranks = {'out12': [0]}  # ä»rank 0æ¥æ”¶out12
    self.send_ranks = {'out25': [2]}     # å‘é€out25åˆ°rank 2 (å®é™…ä¸Šæ˜¯rank 3)
    
    # æ³¨æ„: è¿™é‡Œæœ‰ä¸ªé”™è¯¯ï¼Œåº”è¯¥æ˜¯å‘é€åˆ°rank 3ï¼Œè¯´æ˜é…ç½®éœ€è¦è°ƒæ•´
    # æ­£ç¡®çš„åº”è¯¥æ˜¯:
    self.send_ranks = {'out25': [3]}     # å‘é€åˆ°ä¸‹ä¸€ä¸ªstageçš„ç¬¬ä¸€ä¸ªrank
    
    # 5. åˆ†é…tensor tags
    self.tensor_tags = {
        'input0': 1,
        'input1': 2,
        'input2': 3,
        'out12': 4,
        'out25': 5,
        'out38': 6,
        'target': 7,
        'ack': 8
    }
    
    # 6. åˆ›å»ºCommunicationHandler
    self.comm_handler = communication.CommunicationHandler(
        master_addr='localhost',
        master_port=12345,
        rank=2,
        local_rank=2,
        num_ranks_in_server=1,
        world_size=4,
        fp16=False,
        backend='gloo'
    )
    
    # 7. å°†æ¨¡å—ç§»åˆ°GPU
    modules = self.modules_with_dependencies.modules()
    for i in range(len(modules)):
        modules[i] = modules[i].cuda()  # ç§»åˆ°GPU 2
    
    # 8. åˆå§‹åŒ–é€šä¿¡handler
    self.comm_handler.initialize(
        self.receive_ranks,
        self.send_ranks,
        self.tensor_tags,
        ...
    )
```

---

## å®æˆ˜3: ä¸€æ¬¡è®­ç»ƒè¿­ä»£çš„å®Œæ•´æµç¨‹

### åœºæ™¯ï¼š4ä¸ªstagesçš„æµæ°´çº¿æ‰§è¡Œ

å‡è®¾batch_size=16ï¼Œæ¯ä¸ªminibatch=4ï¼Œåˆ™æœ‰4ä¸ªminibatchesã€‚

#### æ—¶é—´çº¿ç¤ºæ„å›¾

```
Time  |  Stage 0 (Rank 0)  |  Stage 1 (Rank 1)  |  Stage 2 (Rank 2)  |  Stage 3 (Rank 3)
------+--------------------+--------------------+--------------------+-------------------
  0   |  F0 (forward mb0)  |                    |                    |
  1   |  F1                |  F0                |                    |
  2   |  F2                |  F1                |  F0                |
  3   |  F3                |  F2                |  F1                |  F0
  4   |  B3 (backward mb3) |  F3                |  F2                |  F1
  5   |  B2                |  B3                |  F3                |  F2
  6   |  B1                |  B2                |  B3                |  F3
  7   |  B0                |  B1                |  B2                |  B3
  8   |                    |  B0                |  B1                |  B2
  9   |                    |                    |  B0                |  B1
 10   |                    |                    |                    |  B0
```

#### è¯¦ç»†ä»£ç è¿½è¸ªï¼šRank 2 (Stage 2) çš„æ‰§è¡Œ

**æ–‡ä»¶**: `runtime.py`, `run_training_iteration()`

```python
def run_training_iteration(self, num_iterations):
    """
    å¯¹äºRank 2:
    - num_warmup_minibatches = 2 (éœ€è¦ç­‰å¾…å‰2ä¸ªstage)
    - num_iterations = 4 (4ä¸ªminibatches)
    """
    
    # ===== Warmup é˜¶æ®µ =====
    
    # Iteration 0: åªæ¥æ”¶å’Œå‰å‘
    for i in range(self.num_warmup_minibatches):  # i=0,1
        # 1. æ¥æ”¶æ¥è‡ªStage 1çš„æ¿€æ´»å€¼
        self.receive_tensors_forward()
        #   ä»rank 1æ¥æ”¶ out25
        #   self.tensors = [{'out25': tensor}]
        
        # 2. æ‰§è¡Œå‰å‘ä¼ æ’­
        self.run_forward()
        #   æ‰§è¡Œ Stage 2 çš„forward
        #   self.tensors[-1]['out38'] = stage2_module(self.tensors[-1]['out25'])
        
        # 3. å‘é€æ¿€æ´»å€¼åˆ°Stage 3
        self.send_tensors_forward()
        #   å‘é€ out38 åˆ° rank 3
        
        self.forward_minibatch_id += 1  # 0 -> 1 -> 2
    
    # æ­¤æ—¶ forward_minibatch_id = 2, backward_minibatch_id = 0
    
    # ===== ç¨³å®šé˜¶æ®µ (1F1B) =====
    
    for i in range(num_iterations - self.num_warmup_minibatches):  # i=0,1
        # Iteration 2: 1æ¬¡å‰å‘ + 1æ¬¡åå‘
        
        # 4. ç»§ç»­å‰å‘
        self.receive_tensors_forward()  # æ¥æ”¶mb2çš„æ¿€æ´»å€¼
        self.run_forward()
        self.send_tensors_forward()
        self.forward_minibatch_id += 1  # 2 -> 3
        
        # 5. åå‘ä¼ æ’­
        self.receive_tensors_backward()
        #   ä»rank 3æ¥æ”¶ out38çš„æ¢¯åº¦
        #   self.gradients['out38'] = grad_tensor
        
        self.run_backward()
        #   æ‰§è¡Œåå‘ä¼ æ’­
        #   è®¡ç®— out25 çš„æ¢¯åº¦
        #   self.gradients['out25'] = ...
        
        self.send_tensors_backward()
        #   å‘é€ out25çš„æ¢¯åº¦ åˆ° rank 1
        
        self.backward_minibatch_id += 1  # 0 -> 1
    
    # ===== Cooldown é˜¶æ®µ =====
    
    for i in range(self.num_warmup_minibatches):  # i=0,1
        # åªæ‰§è¡Œåå‘
        self.receive_tensors_backward()
        self.run_backward()
        self.send_tensors_backward()
        self.backward_minibatch_id += 1  # 1 -> 2 -> 3
```

---

## å®æˆ˜4: é€šä¿¡ç»†èŠ‚è¿½è¸ª

### åœºæ™¯ï¼šRank 1å‘é€æ¿€æ´»å€¼åˆ°Rank 2

#### Rank 1 (å‘é€æ–¹)
**æ–‡ä»¶**: `runtime.py`, `send_tensors_forward()`

```python
def send_tensors_forward(self):
    # Stage 1å‘é€ out25 åˆ° Stage 2
    for output_name in self.send_ranks:  # output_name = 'out25'
        if output_name == "ack":
            continue
        
        # è·å–è¦å‘é€çš„tensor
        tensor = self.tensors[-1][output_name]
        # tensor.shape = (4, 128, 1024)  # (batch, seq_len, hidden)
        
        # è°ƒç”¨é€šä¿¡handlerå‘é€
        self.comm_handler.send(
            output_name,                          # 'out25'
            tensor,                               # æ¿€æ´»å€¼tensor
            forward_minibatch_id=self.forward_minibatch_id,  # 2
            backward_minibatch_id=self.backward_minibatch_id, # 0
            backward=False
        )
    
    # å¢åŠ æ¶ˆæ¯ç´¢å¼•
    self.comm_handler.increment_messaging_index(sending=True)
```

**æ–‡ä»¶**: `communication.py`, `send()`

```python
def send(self, tensor_name, tensor, forward_minibatch_id, 
         backward_minibatch_id, backward=False):
    # tensor_name = 'out25', backward = False
    
    # 1. ç¡®å®šç›®æ ‡rank
    if not backward:
        dst_ranks = self.send_ranks[tensor_name]  # [2]
    
    # 2. é€‰æ‹©ä¸€ä¸ªç›®æ ‡rankï¼ˆå¦‚æœæœ‰å¤šä¸ªï¼Œè½®è¯¢ï¼‰
    dst_rank = dst_ranks[self.messaging_index_send % len(dst_ranks)]  # rank 2
    
    # 3. è·å–tensorçš„tag
    tag = self.tensor_tags[tensor_name]  # å‡è®¾ tag=5
    
    # 4. æ·»åŠ minibatch_idåˆ°tag
    adjusted_tag = tag * 100000 + forward_minibatch_id
    # adjusted_tag = 5 * 100000 + 2 = 500002
    
    # 5. å°†tensoræ”¾å…¥å‘é€é˜Ÿåˆ—
    self.forward_send_queues[tensor_name].put((tensor, dst_rank, adjusted_tag))
    
    # åå°çº¿ç¨‹ä¼šå¼‚æ­¥å‘é€:
    # dist.send(tensor=tensor, dst=2, tag=500002)
```

#### Rank 2 (æ¥æ”¶æ–¹)
**æ–‡ä»¶**: `runtime.py`, `receive_tensors_forward()`

```python
def receive_tensors_forward(self):
    self.tensors.append({})  # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨è¿™ä¸ªminibatchçš„tensors
    
    # Stage 2éœ€è¦æ¥æ”¶ out25
    for input_name in self.receive_ranks:  # input_name = 'out25'
        if input_name == "ack":
            continue
        
        # è°ƒç”¨é€šä¿¡handleræ¥æ”¶
        received_tensor = self.comm_handler.recv(
            input_name,                               # 'out25'
            forward_minibatch_id=self.forward_minibatch_id,  # 2
            backward_minibatch_id=self.backward_minibatch_id, # 0
            backward=False
        )
        
        self.tensors[-1][input_name] = received_tensor
        # self.tensors[-1] = {'out25': received_tensor}
    
    self.comm_handler.increment_messaging_index(sending=False)
```

**æ–‡ä»¶**: `communication.py`, `recv()`

```python
def recv(self, tensor_name, forward_minibatch_id, 
         backward_minibatch_id, backward=False):
    # tensor_name = 'out25', backward = False
    
    # 1. ç¡®å®šæºrank
    if not backward:
        src_ranks = self.receive_ranks[tensor_name]  # [1]
    
    # 2. é€‰æ‹©ä¸€ä¸ªæºrank
    src_rank = src_ranks[self.messaging_index_receive % len(src_ranks)]  # rank 1
    
    # 3. è®¡ç®—tag
    tag = self.tensor_tags[tensor_name]  # 5
    adjusted_tag = tag * 100000 + forward_minibatch_id  # 500002
    
    # 4. ä»æ¥æ”¶é˜Ÿåˆ—ä¸­è·å–ï¼ˆåå°çº¿ç¨‹å·²æ¥æ”¶ï¼‰
    result = self.forward_receive_queues[tensor_name].get()
    # result = (received_tensor,)
    
    return result[0]
    
    # åå°çº¿ç¨‹æ‰§è¡Œçš„æ˜¯:
    # buffer = torch.zeros(shape, dtype=dtype, device='cuda')
    # dist.recv(tensor=buffer, src=1, tag=500002)
    # queue.put((buffer,))
```

---

## å®æˆ˜5: Weight Stashingæœºåˆ¶

### åœºæ™¯ï¼šRank 1æ‰§è¡ŒASPæ¨¡å¼è®­ç»ƒ

**èƒŒæ™¯**: 
- Pipelineæ·±åº¦ä¸º4ï¼Œæ‰€ä»¥num_versions=4
- åœ¨æ—¶åˆ»tï¼ŒStage 1å¯èƒ½åœ¨ç”¨v0ç‰ˆæœ¬åšå‰å‘ï¼ŒåŒæ—¶ç”¨v3ç‰ˆæœ¬çš„æ¢¯åº¦æ›´æ–°æƒé‡

#### æƒé‡ç‰ˆæœ¬é˜Ÿåˆ—ç¤ºæ„

```python
# åˆå§‹åŒ–æ—¶
self.queue = deque([
    state_dict_v0,  # æœ€è€
    state_dict_v1,
    state_dict_v2,
    state_dict_v3   # æœ€æ–°
], maxlen=4)

self.latest_version = Version(3)
self.current_version = Version(0)  # ç”¨äºå‰å‘
```

#### ä¸€æ¬¡è®­ç»ƒè¿­ä»£

**æ–‡ä»¶**: `optimizer.py`, `step()`

```python
def step(self):
    # 1. åŠ è½½æ—§ç‰ˆæœ¬æƒé‡ï¼ˆç”¨äºåº”ç”¨æ¢¯åº¦ï¼‰
    self.load_old_params()
    #   ä»é˜Ÿåˆ—å¤´éƒ¨å–å‡ºv0çš„æƒé‡
    #   å°†æ¨¡å‹å‚æ•°è®¾ç½®ä¸ºv0
    
    # 2. åº”ç”¨æ¢¯åº¦æ›´æ–°
    self.base_optimizer.step()
    #   ä½¿ç”¨å½“å‰çš„æ¢¯åº¦æ›´æ–°v0çš„æƒé‡ -> å¾—åˆ°v4
    
    # 3. ä¿å­˜æ–°ç‰ˆæœ¬
    new_state_dict = self.get_params(clone=True)
    self.queue.append(new_state_dict)
    #   é˜Ÿåˆ—å˜ä¸º: [v1, v2, v3, v4]
    #   v0è¢«è‡ªåŠ¨ä¸¢å¼ƒï¼ˆmaxlen=4ï¼‰
    
    # 4. æ›´æ–°ç‰ˆæœ¬å·
    self.latest_version = self.latest_version.incr()  # v3 -> v4
    self.current_version = self.current_version.incr()  # v0 -> v1
    
    # 5. åŠ è½½æ–°ç‰ˆæœ¬ï¼ˆç”¨äºä¸‹æ¬¡å‰å‘ï¼‰
    self.load_new_params()
    #   å°†æ¨¡å‹å‚æ•°è®¾ç½®ä¸ºv4
```

#### ç‰ˆæœ¬å¯¹åº”å…³ç³»

```
Minibatch   Forwardç”¨çš„ç‰ˆæœ¬   Backwardç”¨çš„ç‰ˆæœ¬   æ›´æ–°åçš„ç‰ˆæœ¬
   0            v0                -              -
   1            v1                -              -
   2            v2                -              -
   3            v3                -              -
   4            v4              v0 (mb0çš„æ¢¯åº¦)   v0 -> v4
   5            v5              v1 (mb1çš„æ¢¯åº¦)   v1 -> v5
   6            v6              v2 (mb2çš„æ¢¯åº¦)   v2 -> v6
   ...
```

**å…³é”®ç‚¹**: 
- mb4çš„å‰å‘ç”¨çš„æ˜¯v4ï¼Œä½†åŒæ—¶åœ¨ç”¨mb0çš„æ¢¯åº¦æ›´æ–°v0
- è¿™ä¿è¯äº†æ¢¯åº¦ç‰ˆæœ¬ä¸€è‡´æ€§ï¼šmb0å‰å‘ç”¨v0ï¼Œåå‘ä¹Ÿå¯¹åº”v0

---

## å®æˆ˜6: æ¿€æ´»é‡è®¡ç®—

### åœºæ™¯ï¼šStage 0å¯ç”¨recompute_ratio=0.3

**Stage 0åŒ…å«12ä¸ªblocksï¼Œrecompute_ratio=0.3**

#### å‰å‘ä¼ æ’­æ—¶

**æ–‡ä»¶**: `bert/vpipe.py`, `Stage.forward()`

```python
def forward(self, *args):
    # å‡è®¾Stage 0æœ‰12ä¸ªblocksï¼Œrecompute_ratio=0.3
    # back = int(0.3 * 12) = 3
    # æ‰€ä»¥å3ä¸ªblocksä½¿ç”¨checkpoint
    
    if self.enable_recompute:
        # 1. å‰9ä¸ªblocksæ­£å¸¸æ‰§è¡Œ
        exec(self.no_cp)
        # self.no_cp åŒ…å«:
        #   out0 = args[0]
        #   out1 = self.layer1(out0)
        #   ...
        #   out9 = self.layer9(out8)
        #   cp_out = cp.checkpoint(self.cp_forward, out9, self.dummy)
        #   self.out = (cp_out[0], cp_out[1], ...)
        
        # 2. å3ä¸ªblocksé€šè¿‡checkpointæ‰§è¡Œ
        # checkpointä¸ä¼šä¿å­˜ä¸­é—´æ¿€æ´»å€¼
        
    else:
        # å®Œå…¨æ­£å¸¸æ‰§è¡Œ
        exec(self.no_cp)
    
    return self.out
```

#### åå‘ä¼ æ’­æ—¶

```python
# å½“è®¡ç®—æ¢¯åº¦æ—¶ï¼ŒPyTorchçš„autogradä¼š:
# 1. å¯¹äºå‰9ä¸ªblocks: ç›´æ¥ä½¿ç”¨ä¿å­˜çš„æ¿€æ´»å€¼
# 2. å¯¹äºå3ä¸ªblocks: é‡æ–°æ‰§è¡Œcp_forwardæ¥è®¡ç®—æ¿€æ´»å€¼

def cp_forward(self, *args):
    # é‡è®¡ç®—å3ä¸ªblocks
    exec(self.cp)
    # self.cp åŒ…å«:
    #   out9 = args[0]
    #   out10 = self.layer10(out9)
    #   out11 = self.layer11(out10)
    #   out12 = self.layer12(out11)
    #   self.cp_out = (out10, out11, out12)
    return self.cp_out
```

#### å†…å­˜èŠ‚çœè®¡ç®—

å‡è®¾æ¯ä¸ªblockçš„æ¿€æ´»å€¼å 100MBï¼š
- **ä¸é‡è®¡ç®—**: 12 * 100MB = 1200MB
- **é‡è®¡ç®—30%**: 9 * 100MB = 900MB (èŠ‚çœ300MB)
- **ä»£ä»·**: åå‘æ—¶å¤š3æ¬¡å‰å‘è®¡ç®—

---

## å®æˆ˜7: è°ƒè¯•æŠ€å·§å®æˆ˜

### æŠ€å·§1: æ‰“å°æ¯ä¸ªstageçš„æ‰§è¡Œæ—¶é—´

åœ¨ `runtime.py` ä¸­æ·»åŠ ï¼š

```python
def run_training_iteration(self, num_iterations, start_iter=0):
    import time
    
    for i in range(start_iter, num_iterations):
        # å‰å‘
        start_time = time.time()
        self.receive_tensors_forward()
        recv_time = time.time() - start_time
        
        start_time = time.time()
        self.run_forward()
        forward_time = time.time() - start_time
        
        start_time = time.time()
        self.send_tensors_forward()
        send_time = time.time() - start_time
        
        if i % 10 == 0:
            print(f"[Rank {self.rank}] Iter {i}: "
                  f"recv={recv_time*1000:.2f}ms, "
                  f"forward={forward_time*1000:.2f}ms, "
                  f"send={send_time*1000:.2f}ms")
```

### æŠ€å·§2: éªŒè¯é€šä¿¡çš„tensorå€¼

```python
def send_tensors_forward(self):
    for output_name in self.send_ranks:
        tensor = self.tensors[-1][output_name]
        
        # æ‰“å°tensorç»Ÿè®¡ä¿¡æ¯
        print(f"[Rank {self.rank}] Sending {output_name}: "
              f"shape={tensor.shape}, "
              f"mean={tensor.mean().item():.4f}, "
              f"std={tensor.std().item():.4f}, "
              f"min={tensor.min().item():.4f}, "
              f"max={tensor.max().item():.4f}")
        
        self.comm_handler.send(...)
```

### æŠ€å·§3: è¿½è¸ªæ¢¯åº¦æµ

```python
def run_backward(self):
    # æ‰§è¡Œåå‘å‰
    for name, param in self.modules()[0].named_parameters():
        if param.grad is not None:
            print(f"[Rank {self.rank}] Before backward, {name}.grad = "
                  f"{param.grad.norm().item():.6f}")
    
    # æ‰§è¡Œåå‘ä¼ æ’­
    ...
    
    # æ‰§è¡Œåå‘å
    for name, param in self.modules()[0].named_parameters():
        if param.grad is not None:
            print(f"[Rank {self.rank}] After backward, {name}.grad = "
                  f"{param.grad.norm().item():.6f}")
```

### æŠ€å·§4: å¯è§†åŒ–pipeline

åˆ›å»ºä¸€ä¸ªæ—¥å¿—è®°å½•å™¨ï¼š

```python
# åœ¨runtime.pyå¼€å¤´æ·»åŠ 
import json
import time

class PipelineLogger:
    def __init__(self, rank, log_file):
        self.rank = rank
        self.log_file = log_file
        self.events = []
    
    def log_event(self, event_type, minibatch_id):
        self.events.append({
            'rank': self.rank,
            'event': event_type,
            'minibatch': minibatch_id,
            'time': time.time()
        })
    
    def save(self):
        with open(self.log_file, 'w') as f:
            json.dump(self.events, f)

# åœ¨StageRuntimeä¸­ä½¿ç”¨
self.logger = PipelineLogger(self.rank, f'pipeline_rank{self.rank}.json')

def receive_tensors_forward(self):
    self.logger.log_event('recv_forward_start', self.forward_minibatch_id)
    ...
    self.logger.log_event('recv_forward_end', self.forward_minibatch_id)
```

ç„¶åç”¨Pythonè„šæœ¬å¯è§†åŒ–ï¼š

```python
import json
import matplotlib.pyplot as plt

# è¯»å–æ‰€æœ‰ranksçš„æ—¥å¿—
events = []
for rank in range(4):
    with open(f'pipeline_rank{rank}.json', 'r') as f:
        events.extend(json.load(f))

# æŒ‰æ—¶é—´æ’åº
events.sort(key=lambda x: x['time'])

# ç»˜åˆ¶ç”˜ç‰¹å›¾
fig, ax = plt.subplots(figsize=(12, 6))
colors = {'recv_forward': 'blue', 'forward': 'green', 'send_forward': 'red'}

for event in events:
    ax.barh(event['rank'], 0.1, left=event['time'], color=colors.get(event['event'], 'gray'))

ax.set_xlabel('Time (s)')
ax.set_ylabel('Rank')
ax.set_title('Pipeline Execution Timeline')
plt.savefig('pipeline_timeline.png')
```

---

## æ€»ç»“

é€šè¿‡è¿™äº›å®æˆ˜ç¤ºä¾‹ï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

1. **ç†è§£å¯åŠ¨æµç¨‹**: ä»driveråˆ°runtimeçš„å®Œæ•´é“¾è·¯
2. **è¿½è¸ªæ‰§è¡Œæµ**: å•ä¸ªrankçš„åˆå§‹åŒ–å’Œè¿è¡Œ
3. **åˆ†ææµæ°´çº¿**: 4ä¸ªstageså¦‚ä½•ååŒå·¥ä½œ
4. **ç†è§£é€šä¿¡**: tensorå¦‚ä½•åœ¨stagesé—´ä¼ é€’
5. **æŒæ¡Weight Stashing**: æƒé‡ç‰ˆæœ¬å¦‚ä½•ç®¡ç†
6. **ç†è§£é‡è®¡ç®—**: å¦‚ä½•ç”¨æ—¶é—´æ¢å†…å­˜
7. **è°ƒè¯•æŠ€å·§**: å¦‚ä½•å®šä½å’Œåˆ†æé—®é¢˜

å»ºè®®ä½ å®é™…è¿è¡Œä»£ç ï¼Œæ·»åŠ è¿™äº›è°ƒè¯•è¯­å¥ï¼Œè§‚å¯Ÿå®é™…çš„æ‰§è¡Œæƒ…å†µï¼

