# VPipe 变量速查表

## 🔖 快速索引

### StageRuntime 类核心变量 (runtime.py)

#### 基础标识信息
| 变量名 | 类型 | 含义 | 示例值 |
|--------|------|------|--------|
| `self.rank` | int | 全局进程ID | 0-7 (8 GPUs) |
| `self.local_rank` | int | 节点内GPU ID | 0-3 |
| `self.stage` | int | 当前stage编号 | 0, 1, 2, 3 |
| `self.rank_in_stage` | int | 在stage内的rank | 0, 1 (数据并行) |
| `self.num_ranks` | int | 总进程数 | 8 |
| `self.num_stages` | int | 总stage数 | 4 |
| `self.num_ranks_in_stage` | int | 当前stage内GPU数 | 2 (数据并行度) |

#### 流水线控制
| 变量名 | 类型 | 含义 | 说明 |
|--------|------|------|------|
| `self.forward_minibatch_id` | int | 当前前向传播的minibatch编号 | 递增计数器 |
| `self.backward_minibatch_id` | int | 当前反向传播的minibatch编号 | 递增计数器 |
| `self.num_warmup_minibatches` | int | warmup阶段的minibatch数量 | 用于pipeline填充 |
| `self.forward_only` | bool | 是否仅前向传播 | eval模式为True |

#### Stage间通信
| 变量名 | 类型 | 含义 | 示例 |
|--------|------|------|------|
| `self.send_ranks` | dict | 需要发送的张量及目标ranks | `{'out5': [2, 3]}` |
| `self.receive_ranks` | dict | 需要接收的张量及源ranks | `{'input0': [0, 1]}` |
| `self.tensor_tags` | dict | 张量名到通信tag的映射 | `{'input0': 1, 'out5': 2}` |
| `self.ranks_in_previous_stage` | list | 前一个stage的所有ranks | `[0, 1]` |
| `self.ranks_in_next_stage` | list | 后一个stage的所有ranks | `[4, 5]` |

#### 张量管理
| 变量名 | 类型 | 含义 | 说明 |
|--------|------|------|------|
| `self.tensors` | list[dict] | 存储每个minibatch的激活值 | `[{'input0': tensor, 'out5': tensor}]` |
| `self.gradients` | dict | 存储梯度 | `{'out5': gradient_tensor}` |
| `self.tensor_shapes` | dict | 张量形状信息 | `{'input0': (batch_size, seq_len, hidden)}` |
| `self.training_tensor_shapes` | dict | 训练时的张量形状 | 用于预分配buffer |
| `self.eval_tensor_shapes` | dict | 评估时的张量形状 | 可能与训练不同 |
| `self.training_tensor_dtypes` | dict | 张量数据类型 | `{'input0': torch.float32}` |

#### 模型相关
| 变量名 | 类型 | 含义 | 说明 |
|--------|------|------|------|
| `self.modules_with_dependencies` | ModulesWithDependencies | 当前stage的模块及依赖 | 包含nn.Module列表 |
| `self.is_criterion` | bool | 是否是最后一个stage | 最后stage包含loss计算 |
| `self.master_parameters` | list | 主参数（优化器更新用） | FP16时为FP32副本 |
| `self.model_parameters` | list | 模型参数（推理用） | FP16模式下使用 |
| `self.enable_recompute` | bool | 是否启用重计算 | 节省激活值内存 |

#### 性能统计
| 变量名 | 类型 | 含义 | 说明 |
|--------|------|------|------|
| `self.forward_stats` | RuntimeStats | 前向传播统计信息 | 时间、通信量等 |
| `self.backward_stats` | RuntimeStats | 反向传播统计信息 | 时间、通信量等 |
| `self.verbose_freq` | int | 详细日志打印频率 | 每N个iteration打印 |

#### 训练超参数
| 变量名 | 类型 | 含义 | 说明 |
|--------|------|------|------|
| `self.fp16` | bool | 是否使用FP16训练 | 节省内存和加速 |
| `self.loss_scale` | float | loss缩放因子 | FP16训练防止下溢 |
| `self.distributed_backend` | str | 分布式后端 | 'gloo' 或 'nccl' |

---

## CommunicationHandler 类核心变量 (communication.py)

| 变量名 | 类型 | 含义 | 说明 |
|--------|------|------|------|
| `self.rank` | int | 全局rank | 与StageRuntime一致 |
| `self.local_rank` | int | 本地rank | 用于指定GPU |
| `self.world_size` | int | 全局进程总数 | 等于总GPU数 |
| `self.num_ranks_in_server` | int | 单节点内的GPU数 | 用于判断是否GPU-GPU通信 |
| `self.backend` | str | 通信后端 | 'gloo' 或 'nccl' |
| `self.ranks_in_server` | list | 同节点内其他ranks | 用于广播通信 |
| `self.connection_list` | list | GPU-GPU通信的连接信息 | `[[tag, rank], ...]` |
| `self.process_groups` | dict | 进程组字典 | 用于广播操作 |
| `self.tensor_tags` | dict | 张量通信tag映射 | 从StageRuntime传入 |
| `self.target_tensor_names` | set | 目标张量名称集合 | 如labels |

### 通信队列相关
| 变量名 | 类型 | 含义 | 说明 |
|--------|------|------|------|
| `self.forward_receive_queues` | dict | 前向接收队列 | `{tensor_name: Queue}` |
| `self.backward_receive_queues` | dict | 反向接收队列 | `{tensor_name: Queue}` |
| `self.forward_send_queues` | dict | 前向发送队列 | `{tensor_name: Queue}` |
| `self.backward_send_queues` | dict | 反向发送队列 | `{tensor_name: Queue}` |
| `self.num_forward_threads` | int | 前向通信线程数 | 等于待接收tensor数 |
| `self.num_backward_threads` | int | 反向通信线程数 | 等于待接收tensor数 |

### 消息索引（用于数据并行）
| 变量名 | 类型 | 含义 | 说明 |
|--------|------|------|------|
| `self.messaging_index_receive` | int | 接收消息的源rank索引 | 轮询不同源 |
| `self.messaging_index_send` | int | 发送消息的目标rank索引 | 轮询不同目标 |

---

## OptimizerWithWeightStashing 类核心变量 (optimizer.py)

| 变量名 | 类型 | 含义 | 说明 |
|--------|------|------|------|
| `self.base_optimizer` | torch.optim.Optimizer | 基础优化器 | Adam/SGD/LAMB等 |
| `self.modules` | list | 模型模块列表 | 用于state_dict操作 |
| `self.master_parameters` | list | 主参数 | 优化器直接更新的参数 |
| `self.model_parameters` | list | 模型参数 | FP16模式下的FP16副本 |
| `self.loss_scale` | float | loss缩放 | FP16训练用 |
| `self.num_versions` | int | 存储的权重版本数 | 通常等于pipeline深度 |
| `self.latest_version` | Version | 最新权重版本号 | 递增的版本对象 |
| `self.current_version` | Version | 当前使用的版本号 | 滞后于latest |
| `self.queue` | deque | 权重版本队列 | 存储state_dict的循环队列 |
| `self.update_interval` | int | 权重更新间隔 | macrobatch模式下>1 |
| `self.batch_counter` | int | batch计数器 | 用于控制更新频率 |

---

## Configuration Maps (配置映射数据结构)

### module_to_stage_map
**类型**: `list[int]`  
**含义**: 每个模块对应的stage编号  
**示例**:
```python
[0, 0, 0, ..., 0, 1, 1, ..., 1, 2, 2, ..., 2, 3, 3, ..., 3]
# 前12个模块在stage 0，接下来13个在stage 1，以此类推
```

### stage_to_rank_map
**类型**: `dict[int, list[int]]`  
**含义**: 每个stage包含的rank列表  
**示例**:
```python
{
    0: [0, 1],      # Stage 0在rank 0和1上（数据并行）
    1: [2, 3],      # Stage 1在rank 2和3上
    2: [4, 5],      # Stage 2在rank 4和5上
    3: [6, 7]       # Stage 3在rank 6和7上
}
```

### stage_to_depth_map
**类型**: `dict[str, int]`  
**含义**: 每个stage的warmup深度（从partition文件计算得出）  
**示例**:
```python
{
    "0": 0,   # Stage 0不需要warmup
    "1": 2,   # Stage 1需要2个minibatch的warmup
    "2": 4,   # Stage 2需要4个minibatch的warmup
    "3": 6    # Stage 3需要6个minibatch的warmup
}
```

---

## Partition 配置 (JSON文件)

### vpipe.json 结构
```json
{
    "partition": [12, 13, 13, 11],
    "recompute_ratio": [0.3, 0, 0, 0]
}
```

| 字段 | 类型 | 含义 | 说明 |
|------|------|------|------|
| `partition` | list[int] | 每个stage的层数 | 总和应等于模型总层数 |
| `recompute_ratio` | list[float] | 每个stage的重计算比例 | 0.0-1.0，通常只有第一个stage>0 |

---

## YAML 配置文件关键字段

| 字段 | 类型 | 含义 | 示例 |
|------|------|------|------|
| `directory` | str | 模型代码目录 | 'bert' |
| `module` | str | 模块名称 | 'vgpus=4' |
| `partition` | str | 分区配置文件路径 | 'vgpus=4/vpipe.json' |
| `config_file` | str | 模型配置文件路径 | 'vgpus=4/mp_conf.json' |
| `machines` | list[str] | 机器:GPU列表 | ['localhost:0', 'localhost:1'] |
| `sync_mode` | str | 同步模式 | 'asp' / 'bsp' |
| `distributed_backend` | str | 分布式后端 | 'gloo' / 'nccl' |
| `model_type` | str | 模型类型 | 'bert' / 'translation' |
| `data_dir` | str | 数据集目录 | '/path/to/dataset' |
| `log_directory` | str | 日志输出目录 | '/path/to/logs' |
| `container` | str | Singularity容器路径 | '/path/to/vpipe.sif' |
| `batch_size` | int | 全局batch大小 | 16 |
| `learning_rate` | float | 学习率 | 0.03 |
| `learning_rate_policy` | str | 学习率策略 | 'polynomial' / 'step' |
| `weight_decay` | float | 权重衰减 | 0.01 |
| `epochs` | int | 训练轮数 | 2 |
| `print_frequency` | int | 打印频率 | 100 |
| `verbose_frequency` | int | 详细日志频率 | 0 (不打印) |
| `recompute` | bool | 是否启用重计算 | true / false |
| `macrobatch` | bool | 是否启用macrobatch | true / false |
| `synthetic_data` | bool | 是否使用合成数据 | true / false |

---

## 常用函数签名

### runtime.py

```python
def receive_tensors_forward():
    """接收前向传播所需的输入张量"""
    
def send_tensors_forward():
    """发送前向传播的输出张量到下游stage"""
    
def run_forward(recompute_step=False):
    """执行前向传播
    Args:
        recompute_step: 是否为重计算步骤（反向时使用）
    """
    
def receive_tensors_backward():
    """接收反向传播的梯度张量"""
    
def send_tensors_backward():
    """发送反向传播的梯度到上游stage"""
    
def run_backward():
    """执行反向传播"""
    
def run_training_iteration(num_iterations, start_iter=0):
    """运行训练迭代
    Args:
        num_iterations: 总迭代次数
        start_iter: 起始迭代编号
    Returns:
        (iteration_time, loss): 迭代时间和loss值
    """
```

### communication.py

```python
def send(tensor_name, tensor, forward_minibatch_id, 
         backward_minibatch_id, backward=False):
    """发送张量
    Args:
        tensor_name: 张量名称
        tensor: 要发送的张量
        forward_minibatch_id: 前向minibatch ID
        backward_minibatch_id: 反向minibatch ID
        backward: 是否为反向传播
    """

def recv(tensor_name, forward_minibatch_id, 
         backward_minibatch_id, backward=False):
    """接收张量
    Args:
        tensor_name: 张量名称
        forward_minibatch_id: 前向minibatch ID
        backward_minibatch_id: 反向minibatch ID
        backward: 是否为反向传播
    Returns:
        received_tensor: 接收到的张量
    """

def wait():
    """等待所有通信完成"""

def start_helper_threads(num_iterations, forward_only):
    """启动后台通信线程
    Args:
        num_iterations: 总迭代次数
        forward_only: 是否仅前向传播
    """
```

### optimizer.py

```python
def load_old_params():
    """加载旧版本的权重（用于应用梯度）"""

def load_new_params():
    """加载新版本的权重（用于前向传播）"""

def step(update_master_weights=True):
    """执行优化器step
    Args:
        update_master_weights: 是否更新主权重
    """
```

---

## 调试常用打印语句

### 追踪执行流程
```python
print(f"[Rank {self.rank}|Stage {self.stage}] "
      f"Forward minibatch {self.forward_minibatch_id}")
```

### 查看通信状态
```python
print(f"[Rank {self.rank}] Sending {tensor_name} to {self.send_ranks[tensor_name]}")
print(f"[Rank {self.rank}] Receiving {tensor_name} from {self.receive_ranks[tensor_name]}")
```

### 查看张量形状
```python
print(f"Tensor {name}: shape={tensor.shape}, device={tensor.device}")
```

### 查看版本信息
```python
print(f"[Optimizer] Current version: {self.current_version}, "
      f"Latest version: {self.latest_version}")
```

### 查看时间统计
```python
print(f"Forward time: {self.forward_stats.stats['forward_time']:.4f}s")
print(f"Backward time: {self.backward_stats.stats['backward_time']:.4f}s")
print(f"Communication size: {self.forward_stats.stats['receive_tensors_size']/1024/1024:.2f} MB")
```

---

## 典型调试场景

### 场景1: 追踪一个tensor的完整生命周期
```python
# 在 runtime.py 中添加
def send_tensors_forward(self):
    for output_name in self.send_ranks:
        tensor = self.tensors[-1][output_name]
        print(f"[{self.rank}] Sending {output_name}: "
              f"shape={tensor.shape}, norm={tensor.norm():.4f}")
        # ... 原有代码
```

### 场景2: 验证权重版本切换
```python
# 在 optimizer.py 中添加
def load_old_params(self):
    old_version = self.current_version
    # ... 原有代码
    print(f"[Optimizer] Loaded old params: version {old_version}")
```

### 场景3: 检查stage分配是否正确
```python
# 在 runtime.py 的 __init__ 中添加
if self.rank == 0:
    for stage_id, ranks in stage_to_rank_map.items():
        modules = stage_to_module_map[stage_id]
        print(f"Stage {stage_id}: ranks={ranks}, modules={modules}")
```

---

## 快速诊断问题

| 现象 | 可能原因 | 检查变量 |
|------|----------|----------|
| 训练卡住 | 通信死锁 | `send_ranks`, `receive_ranks` |
| OOM (内存溢出) | batch太大或激活值过多 | `batch_size`, `recompute_ratio` |
| Loss不收敛 | 学习率不当或梯度版本错误 | `learning_rate`, `num_versions` |
| 吞吐量低 | partition不平衡 | `partition`, 各stage的层数 |
| 通信开销大 | stage切分过细 | `num_stages`, `partition` |
| 版本错误 | weight stashing问题 | `latest_version`, `current_version` |

---

## 总结

这个速查表涵盖了VPipe中最重要的变量和数据结构。建议：

1. **初学者**: 重点关注 `rank`, `stage`, `send_ranks`, `receive_ranks`
2. **进阶学习**: 深入理解 `num_versions`, `queue`, `tensor_tags`
3. **性能调优**: 关注 `partition`, `recompute_ratio`, `batch_size`

在阅读代码时，可以将本文档作为参考，快速理解变量含义。

